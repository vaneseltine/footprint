{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "acc539be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import httpx\n",
    "\n",
    "# for i in range(10):\n",
    "#     clear_output(wait=True)\n",
    "#     print(i)\n",
    "#     time.sleep(0.1)\n",
    "\n",
    "DATA_DIR = Path('./data')\n",
    "WORKS_DATA_DIR = DATA_DIR / 'works_of_institutions'\n",
    "AUTHORS_DIR = DATA_DIR / 'works_by_author'\n",
    "print(len(list(WORKS_DATA_DIR.glob('*.json'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec21ef7",
   "metadata": {},
   "source": [
    "## institutional works to author_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d5d7517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openalex.org/W3087139986\n",
      "https://openalex.org/A2814149936 Yuzi Tian ['University of Michigan–Ann Arbor', 'Department of Rheumatology and Immunology, Xiangya Hospital, Central South University, Changsha, Hunan, China.']\n",
      "https://openalex.org/A2607418774 Qiufang Deng ['University of Michigan–Ann Arbor', 'Department of Rheumatology and Immunology, Xiangya Hospital, Central South University, Changsha, Hunan, China.']\n",
      "https://openalex.org/A2274029971 Hasan B. Alam ['University of Michigan–Ann Arbor']\n",
      "https://openalex.org/A2107458222 Yongqing Li ['University of Michigan–Ann Arbor']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "work_file = WORKS_DATA_DIR / 'work-2020-true-1.json'\n",
    "\n",
    "with work_file.open('r', encoding='UTF-8') as infile:\n",
    "    work_json = json.load(infile)\n",
    "print(len(work_json['results']))\n",
    "\n",
    "print(work_json['results'][0].keys())\n",
    "for r in work_json['results']:\n",
    "    clear_output(wait=True)\n",
    "    print(r['id'])\n",
    "    matched_authors = [x for x in r['authorships'] if any(i for i in x['institutions'] if i['id'] in SAMPLE_INSTITUTIONS)]\n",
    "    for auth in matched_authors:\n",
    "        print(auth['author']['id'], auth['author']['display_name'], [i['display_name'] for i in auth['institutions']])\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cb880c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_INSTITUTIONS = (\n",
    "    'https://openalex.org/I27837315',\n",
    "    'https://openalex.org/I4210114445',\n",
    "    'https://openalex.org/I4210151884'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2743ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_ids = set()\n",
    "\n",
    "for work_file in WORKS_DATA_DIR.glob(\"work-*.json\"):\n",
    "    clear_output(wait=True)\n",
    "    print(work_file)\n",
    "    with work_file.open('r', encoding='UTF-8') as infile:\n",
    "        work_json = json.load(infile)\n",
    "    for r in work_json['results']:\n",
    "        print(r['id'])\n",
    "        matched_authors = [x for x in r['authorships'] if any(i for i in x['institutions'] if i.get('id') in SAMPLE_INSTITUTIONS)]\n",
    "        for auth in matched_authors:\n",
    "            author_id = auth['author'].get('id')\n",
    "            if author_id and author_id not in author_ids:\n",
    "                author_ids.add(auth['author']['id'])\n",
    "                print(author_id, auth['author']['display_name'], [i.get('display_name') for i in auth['institutions']])\n",
    "    print('up to', len(author_ids))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ee379fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99174\n"
     ]
    }
   ],
   "source": [
    "authors_out = WORKS_DATA_DIR / 'authors_from_works_of_institutions.json'\n",
    "with authors_out.open('w', encoding='UTF-8') as outfile:\n",
    "    json.dump(list(author_ids), outfile)\n",
    "print(len(author_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a43ebe",
   "metadata": {},
   "source": [
    "### author_id to authored works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6bc05e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTACT_EMAIL = \"matvan@umich.edu\"\n",
    "# A2669589972 was a problem, very large file to load (??), timing out on httpx defaults\n",
    "PER_PAGE = 200\n",
    "REQUEST_TIMEOUT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d479c978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99174"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with authors_out.open('r', encoding='UTF-8') as infile:\n",
    "    authors = list(json.load(infile))\n",
    "len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ff6351cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-31 10:08:50.377025\n",
      "2022-08-31 10:08:51.380112\n"
     ]
    }
   ],
   "source": [
    "def sleep_until_one_second_after(earlier):\n",
    "    target = earlier + dt.timedelta(seconds=1)\n",
    "    while True:\n",
    "        diff = (target - dt.datetime.now()).total_seconds()\n",
    "        if diff <= 0:\n",
    "            return\n",
    "        elif diff <= 0.1:\n",
    "            time.sleep(0.01)\n",
    "        elif diff <= 1.5:\n",
    "            time.sleep(0.1)\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "\n",
    "basically_now = dt.datetime.now()\n",
    "print(basically_now)\n",
    "time.sleep(0.8)\n",
    "sleep_until_one_second_after(basically_now)\n",
    "print(dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "71c7993d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def strip_work(rec):\n",
    "    new_rec = {'id': minimize_id(rec['id'])}\n",
    "    new_rec.update(**{k: rec[k] for k in ('ids', 'publication_year', 'publication_date', 'title', 'type')})\n",
    "    new_rec['author_list'] = [minimize_id(x.get('author', {}).get('id')) for x in rec['authorships']]\n",
    "    new_rec['host_venue_id'] = minimize_id(rec.get('host_venue', {}).get('id'))\n",
    "    new_rec['abstract'] = reconstitute_abstract(rec.get('abstract_inverted_index', {}))\n",
    "    return new_rec\n",
    "\n",
    "# with (AUTHORS_DIR / 'A648449047-001.json').open('r', encoding='UTF-8') as infile:\n",
    "#     test_full_json = json.load(infile)\n",
    "# print(len(test_full_json['results']))\n",
    "\n",
    "# test_item = test_full_json['results'][0]\n",
    "\n",
    "\n",
    "# stripped = strip_work(test_item)\n",
    "# print(len(str(stripped)), len(str(test_item)), '\\n', stripped, '\\n\\n', test_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "42b7daa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openalex.org/A2297362609 A2297362609\n"
     ]
    }
   ],
   "source": [
    "def minimize_id(s):\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    return s.replace(\"https://openalex.org/\", \"\")\n",
    "\n",
    "test_string = 'https://openalex.org/A2297362609'\n",
    "print(test_string, minimize_id(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "31543763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like donuts and i like pie\n"
     ]
    }
   ],
   "source": [
    "def reconstitute_abstract(abstract_inverted_index):\n",
    "    if not abstract_inverted_index:\n",
    "        return ''\n",
    "    reverted = dict()\n",
    "    for k, vs in abstract_inverted_index.items():\n",
    "        for v in vs:\n",
    "            reverted[v] = k\n",
    "    abstract = ' '.join(s for i, s in sorted(reverted.items(), key=lambda x: (x[0])))\n",
    "    return abstract\n",
    "\n",
    "# i like donuts and i like pie\n",
    "test_abstract = {'and': [3], 'donuts': [2], 'i': [0, 4], 'like': [1, 5], 'pie': [6]}\n",
    "print(reconstitute_abstract(test_abstract))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cf02155",
   "metadata": {},
   "source": [
    "## This converted the full raw jsons (17 GB at 38k files) to \n",
    "## the stripped-down versions (a mere 1.9 GB)\n",
    "\n",
    "import os\n",
    "\n",
    "testnum = 0\n",
    "\n",
    "all_raw_json_files = list((DATA_DIR / 'raw_works_by_author').glob(\"*json\"))\n",
    "for i, raw_path in enumerate(all_raw_json_files):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{i+1:>7} of {len(all_raw_json_files)}\", raw_path, end=\" -> \")\n",
    "    raw_size = os.path.getsize(str(raw_path))\n",
    "    path = AUTHORS_DIR / raw_path.name\n",
    "    with raw_path.open('r', encoding='UTF-8') as infile:\n",
    "        raw = json.load(infile)\n",
    "\n",
    "    new_result = {}\n",
    "    new_result['meta'] = raw['meta']\n",
    "    new_result['results'] = [strip_work(w) for w in raw['results']]\n",
    "\n",
    "    with path.open('w', encoding='UTF-8') as outfile:\n",
    "        json.dump(new_result, outfile)\n",
    "    new_size = os.path.getsize(str(path))\n",
    "    print(path, f\"{new_size/raw_size:.1%}\")\n",
    "    raw_path.unlink()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "782707a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_server_hit = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3eb3753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_exhausted(meta):\n",
    "    return meta['per_page'] * meta['page'] >= meta['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8809a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44272 of 99174 A2443597452 1\n",
      "https://api.openalex.org/works?mailto=matvan@umich.edu&filter=author.id:A2443597452&per_page=200&page=1\n",
      "Going back to OpenAlex after 1.0 seconds\n",
      "2022-08-31 14:26:46.294355\n",
      "{'count': 329, 'db_response_time_ms': 46, 'page': 1, 'per_page': 200}\n",
      "data\\works_by_author\\A2443597452-001.json\n",
      "https://api.openalex.org/works?mailto=matvan@umich.edu&filter=author.id:A2443597452&per_page=200&page=2\n",
      "Going back to OpenAlex after 1.0 seconds\n",
      "2022-08-31 14:26:52.676327\n"
     ]
    }
   ],
   "source": [
    "for author_n, full_author_id in enumerate(authors):\n",
    "    clear_output(wait=True)\n",
    "    author_id = full_author_id.replace('https://openalex.org/', '')\n",
    "    print(author_n, 'of', len(authors), author_id, i)\n",
    "\n",
    "    base_url = f\"https://api.openalex.org/works?mailto={CONTACT_EMAIL}\"\n",
    "    filtering = f\"filter=author.id:{author_id}\"\n",
    "    \n",
    "    for i in range(1, 1000):\n",
    "        pagination = f\"per_page={PER_PAGE}&page={i}\"\n",
    "        url = \"&\".join((base_url, filtering, pagination))\n",
    "        print(url)\n",
    "\n",
    "        filename = f\"{author_id}-{i:0>3}.json\"\n",
    "        path = AUTHORS_DIR / filename\n",
    "        \n",
    "        # we're going to gather and handle the errors later, \n",
    "        # not retry now\n",
    "        error_path = DATA_DIR / f\"ERROR-{filename}\"\n",
    "        if error_path.exists():\n",
    "            continue\n",
    "        \n",
    "        # if the path is there, we can just check to see\n",
    "        # if we need to bother fetching the next\n",
    "        if path.exists():\n",
    "            with path.open('r', encoding='UTF-8') as infile:\n",
    "                existing_json = json.load(infile)\n",
    "            existing_meta = existing_json.get('meta')\n",
    "            if count_exhausted(existing_meta):\n",
    "                print(f'Skipping {author_id} based on {path}')\n",
    "                break\n",
    "                \n",
    "        testnum += 1  \n",
    "        \n",
    "        if path.exists():\n",
    "            print(f\"Skipping {path}\")\n",
    "            continue\n",
    "\n",
    "        sleep_until_one_second_after(last_server_hit)\n",
    "        print(f'Going back to OpenAlex after {round((dt.datetime.now() - last_server_hit).total_seconds(), 1)} seconds')\n",
    "        try:            \n",
    "            last_server_hit = dt.datetime.now()\n",
    "            print(last_server_hit)\n",
    "            raw = httpx.get(url, timeout=REQUEST_TIMEOUT).json()\n",
    "            last_server_hit = dt.datetime.now()\n",
    "        except Exception as err:\n",
    "            error_path.write_text(\"\\n\".join((full_author_id, url, str(err))))\n",
    "            print(err)\n",
    "            print(error_path)\n",
    "            continue\n",
    "\n",
    "        print(raw['meta'])\n",
    "        \n",
    "        if raw['results']:\n",
    "            print(path)\n",
    "            \n",
    "            new_result = {}\n",
    "            new_result['meta'] = raw['meta']\n",
    "            new_result['results'] = [strip_work(w) for w in raw['results']]\n",
    "            \n",
    "            with path.open('w', encoding='UTF-8') as outfile:\n",
    "                json.dump(new_result, outfile)\n",
    "               \n",
    "        # This (or an earlier) page has exhausted the record count of this author\n",
    "        if count_exhausted(raw['meta']):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7c64dacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://openalex.org/A2403083729\\nhttps://api.openalex.org/works?mailto=matvan@umich.edu&filter=author.id:A2403083729&per_page=200&page=1\\nhi'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\n\".join((full_author_id, url, str('hi')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
