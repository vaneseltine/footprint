{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da024d42",
   "metadata": {},
   "source": [
    "https://docs.openalex.org/about-the-data/work\n",
    "\n",
    "\n",
    "We're going to filter down to folks on the Ann Arbor campus, and affiliated institutions with >1k works listed. This is only to capture the authors with these affiliations, so occasionally listing Michigan Sea Grant won't exclude someone from the search (unless that's their ONLY listed affiliation).\n",
    "\n",
    "- https://explore.openalex.org/institutions/I27837315 U-M Ann Arbor (695.7k)\n",
    "- https://explore.openalex.org/institutions/I4210114445 Michigan Medicine (2.8k)\n",
    "- https://explore.openalex.org/institutions/I4210151884 C.S. Mott Children's Hospital (2.7k)\n",
    "\n",
    "This produces 953 jsons, up to 20 works each, about 3.1 GB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd61658",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf4a718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import httpx\n",
    "\n",
    "# for i in range(10):\n",
    "#     clear_output(wait=True)\n",
    "#     print(i)\n",
    "#     time.sleep(0.1)\n",
    "\n",
    "DATA_DIR = Path('./data')\n",
    "WORKS_DATA_DIR = DATA_DIR / 'works_of_institutions'\n",
    "if not DATA_DIR.exists():\n",
    "    DATA_DIR.mkdir()\n",
    "if not WORKS_DATA_DIR.exists():\n",
    "    WORKS_DATA_DIR.mkdir()\n",
    "\n",
    "# tester = DATA_DIR / 'test.txt'\n",
    "# tester.touch()\n",
    "# assert tester.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f68d36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API details\n",
    "PER_PAGE = 200 # API max\n",
    "\n",
    "SHARED_FILTERS = \"type:journal-article,has_abstract:true,institutions.id:I27837315|I4210114445|I4210151884\"\n",
    "CONTACT_EMAIL = \"matvan@umich.edu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434d369",
   "metadata": {},
   "source": [
    "## Data building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6d527de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200 OK]>\n",
      "{'count': 245131, 'db_response_time_ms': 80, 'page': 1, 'per_page': 200}\n",
      "https://api.openalex.org/works?mailto=matvan@umich.edu&filter=type:journal-article,has_abstract:true,institutions.id:I27837315|I4210114445|I4210151884&per_page=200&page=1\n",
      "Records:           245,131\n",
      "Pages of records:    1,226\n"
     ]
    }
   ],
   "source": [
    "base_url = f\"https://api.openalex.org/works?mailto={CONTACT_EMAIL}\"\n",
    "filtering = f\"filter={SHARED_FILTERS}\"\n",
    "pagination = f\"per_page={PER_PAGE}&page=1\"\n",
    "url = \"&\".join((base_url, filtering, pagination))\n",
    "r = httpx.get(url)\n",
    "print(r)\n",
    "\n",
    "j = r.json()\n",
    "print(j['meta'])\n",
    "\n",
    "print(url)\n",
    "\n",
    "n_records = j['meta']['count']\n",
    "print(f'Records:          {n_records:>8,}')\n",
    "n_pages = math.ceil(n_records / PER_PAGE)\n",
    "print(f'Pages of records: {n_pages:>8,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fef91016",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.openalex.org/works?mailto=matvan@umich.edu&filter=type:journal-article,has_abstract:true,institutions.id:I27837315|I4210114445|I4210151884,publication_year:1995,is_oa:false&per_page=200&page=13\n",
      "{'count': 2221, 'db_response_time_ms': 19, 'page': 13, 'per_page': 200}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# There's a 10k limit here so... I need to get a little creative\n",
    "\n",
    "records = []\n",
    "# for year in range(2000,2023):\n",
    "for year in range(2022, 1994, -1):\n",
    "    for is_oa in ('true', 'false'):\n",
    "        \n",
    "        filtering = f\"filter={SHARED_FILTERS},publication_year:{year},is_oa:{is_oa}\"\n",
    "        \n",
    "        for i in range(1, 1000):\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            pagination = f\"per_page={PER_PAGE}&page={i}\"\n",
    "            url = \"&\".join((base_url, filtering, pagination))\n",
    "            print(url)\n",
    "\n",
    "            path = WORKS_DATA_DIR / f\"work-{year}-{is_oa}-{i}.json\"\n",
    "            if path.exists():\n",
    "                print(f\"Skipping {path}\")\n",
    "                continue\n",
    "\n",
    "            j = httpx.get(url).json()\n",
    "            print(j['meta'])\n",
    "\n",
    "            count = j['meta']['count']\n",
    "            page = j['meta']['page']\n",
    "            per_page = j['meta']['per_page']\n",
    "\n",
    "\n",
    "            with path.open('w', encoding='UTF-8') as outfile:\n",
    "                json.dump(j, outfile)\n",
    "            if per_page * page >= count:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1d1ac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133 of 1133 data\\works_of_institutions\\work-2022-true-9.json\n",
      "dict_keys(['meta', 'results', 'group_by'])\n",
      "done: 199696\n"
     ]
    }
   ],
   "source": [
    "# next:\n",
    "# validate each json as load()able\n",
    "# -- this will take a minute but will be much easier to refetch any errors rather than deal with the entire json\n",
    "\n",
    "full_file_list = list(WORKS_DATA_DIR.glob('*.json'))\n",
    "n_works = 0\n",
    "for i, path in enumerate(full_file_list):\n",
    "    clear_output(wait=True)\n",
    "    print(i+1, 'of', len(full_file_list), path)\n",
    "    with path.open('r', encoding='UTF-8') as infile:\n",
    "        j = json.load(infile)\n",
    "        print(j.keys())\n",
    "        n_works += len(j['results'])\n",
    "    print('done:', n_works)\n",
    "# if it doesn't error out, we're good"
   ]
  }
 ],
 "metadata": {
  "author": "me",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
